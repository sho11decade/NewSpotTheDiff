# æ¬¡ä¸–ä»£å‹é–“é•ã„æ¢ã—è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - å®Ÿè£…è¨ˆç”»ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

## 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

### 1.1 ç›®æ¨™
AIæŠ€è¡“ï¼ˆSAM 2ã€LaMaã€é¡•è‘—æ€§è§£æï¼‰ã‚’æ´»ç”¨ã—ãŸé–“é•ã„æ¢ã—è‡ªå‹•ç”ŸæˆWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰

### 1.2 é–‹ç™ºæœŸé–“
- **ãƒ•ã‚§ãƒ¼ã‚º1ï¼ˆåŸºç›¤æ§‹ç¯‰ï¼‰**: 2é€±é–“
- **ãƒ•ã‚§ãƒ¼ã‚º2ï¼ˆAIçµ±åˆï¼‰**: 3é€±é–“
- **ãƒ•ã‚§ãƒ¼ã‚º3ï¼ˆUI/UXï¼‰**: 2é€±é–“
- **ãƒ•ã‚§ãƒ¼ã‚º4ï¼ˆãƒ†ã‚¹ãƒˆ/æœ€é©åŒ–ï¼‰**: 2é€±é–“
- **åˆè¨ˆ**: 9é€±é–“

---

## 2. é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚º

### ãƒ•ã‚§ãƒ¼ã‚º1: åŸºç›¤æ§‹ç¯‰ã¨ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### ç›®æ¨™
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤ã®æ§‹ç¯‰ã¨AIãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèª

#### ã‚¿ã‚¹ã‚¯

**1.1 é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**
- [ ] Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ
- [ ] `pyproject.toml` (UV) ã®è¨­å®š
- [ ] Gitãƒªãƒã‚¸ãƒˆãƒªã®åˆæœŸåŒ–
- [ ] `.gitignore` ã®è¨­å®š
- [ ] CUDAç’°å¢ƒã®ç¢ºèªã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

**1.2 AIãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨æ¤œè¨¼**
- [ ] SAM 2ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆTinyãƒ¢ãƒ‡ãƒ«æ¨å¥¨ï¼‰
- [ ] LaMaãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆbig-lamaï¼‰
- [ ] å„ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
- [ ] ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

**1.3 Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸè¨­å®š**
- [ ] Flaskãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆæœŸåŒ–
- [ ] ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ
- [ ] åŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°è¨­å®š
- [ ] è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`config.py`ï¼‰ã®ä½œæˆ
- [ ] ãƒ­ã‚®ãƒ³ã‚°è¨­å®š

**æˆæœç‰©**
- å‹•ä½œã™ã‚‹Flaskã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- å„AIãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèªå®Œäº†
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºç›¤ã®å®Œæˆ

---

### ãƒ•ã‚§ãƒ¼ã‚º2: AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè£…

#### ç›®æ¨™
å„AIæŠ€è¡“ã‚’Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦å®Ÿè£…ã—ã€çµ±åˆ

#### ã‚¿ã‚¹ã‚¯

**2.1 SAM 2ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**
- [ ] `services/sam2_service.py` ã®å®Ÿè£…
  - ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
  - ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
  - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆã®ä½œæˆ
- [ ] ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®å‹•ä½œæ¤œè¨¼

**2.2 é¡•è‘—æ€§è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**
- [ ] `services/saliency_service.py` ã®å®Ÿè£…
  - OpenCV Saliency APIã®çµ±åˆ
  - é¡•è‘—æ€§ãƒãƒƒãƒ—ç”Ÿæˆæ©Ÿèƒ½
  - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé¡•è‘—æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆã®ä½œæˆ
- [ ] å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ

**2.3 LaMaç”»åƒè£œå®Œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**
- [ ] `services/lama_service.py` ã®å®Ÿè£…
  - ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
  - å˜ä¸€ãƒã‚¹ã‚¯è£œå®Œæ©Ÿèƒ½
  - ãƒãƒƒãƒè£œå®Œæ©Ÿèƒ½
- [ ] è£œå®Œå“è³ªã®ãƒ†ã‚¹ãƒˆ
- [ ] ãƒªãƒ•ã‚¡ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ©Ÿèƒ½ã®è©•ä¾¡

**2.4 é–“é•ã„ç”Ÿæˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼**
- [ ] `services/difference_generator.py` ã®å®Ÿè£…
  - ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé¸æŠãƒ­ã‚¸ãƒƒã‚¯
  - é›£æ˜“åº¦èª¿æ•´æ©Ÿèƒ½
  - è‰²å¤‰æ›´æ©Ÿèƒ½
  - ç‰©ä½“è¤‡è£½æ©Ÿèƒ½
  - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã®ä½œæˆ
- [ ] ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ¤œè¨¼

**æˆæœç‰©**
- å…¨AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å®Ÿè£…å®Œäº†
- å˜ä½“/çµ±åˆãƒ†ã‚¹ãƒˆã®å®Œäº†
- ã‚µãƒ³ãƒ—ãƒ«å‡ºåŠ›ã®ç”ŸæˆæˆåŠŸ

---

### ãƒ•ã‚§ãƒ¼ã‚º3: Web UIã¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API

#### ç›®æ¨™
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ§‹ç¯‰

#### ã‚¿ã‚¹ã‚¯

**3.1 ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIã®å®Ÿè£…**
- [ ] `/api/upload` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
  - ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
  - å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
- [ ] `/api/generate` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
  - éåŒæœŸå‡¦ç†ã®å°å…¥
  - ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ç®¡ç†
  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- [ ] `/api/status/<job_id>` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
  - å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
  - é€²æ—æƒ…å ±ã®è¿”å´
- [ ] `/api/result/<job_id>` ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…
  - çµæœãƒ‡ãƒ¼ã‚¿ã®è¿”å´
  - ç”»åƒURLã®ç”Ÿæˆ

**3.2 ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…**
- [ ] ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ (`templates/index.html`)
  - ãƒ’ãƒ¼ãƒ­ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
  - ä½¿ã„æ–¹èª¬æ˜
  - ãƒ‡ãƒ¢å‹•ç”»/ç”»åƒ
- [ ] ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸ (`templates/upload.html`)
  - ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—UI
  - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
  - é›£æ˜“åº¦é¸æŠ
- [ ] å‡¦ç†ä¸­ãƒšãƒ¼ã‚¸ (`templates/processing.html`)
  - ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
  - å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º
  - æ¨å®šæ®‹ã‚Šæ™‚é–“
- [ ] çµæœè¡¨ç¤ºãƒšãƒ¼ã‚¸ (`templates/result.html`)
  - ã‚µã‚¤ãƒ‰ãƒã‚¤ã‚µã‚¤ãƒ‰æ¯”è¼ƒè¡¨ç¤º
  - å·®ç•°ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆæ©Ÿèƒ½
  - ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³

**3.3 JavaScriptå®Ÿè£…**
- [ ] `static/js/upload.js`
  - ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠå‡¦ç†
  - ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—å‡¦ç†
  - ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] `static/js/processing.js`
  - é€²æ—ãƒãƒ¼ãƒªãƒ³ã‚°
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
- [ ] `static/js/result.js`
  - ç”»åƒæ¯”è¼ƒæ©Ÿèƒ½
  - ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç†

**3.4 CSS/ãƒ‡ã‚¶ã‚¤ãƒ³**
- [ ] `static/css/style.css`
  - ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
  - ãƒ¢ãƒ€ãƒ³ãªUI
  - ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³

**æˆæœç‰©**
- å®Œå…¨ãªWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- ç›´æ„Ÿçš„ãªUI/UX
- ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®å‹•ä½œç¢ºèª

---

### ãƒ•ã‚§ãƒ¼ã‚º4: ãƒ†ã‚¹ãƒˆã€æœ€é©åŒ–ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

#### ç›®æ¨™
å“è³ªä¿è¨¼ã€æ€§èƒ½æœ€é©åŒ–ã€åŒ…æ‹¬çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä½œæˆ

#### ã‚¿ã‚¹ã‚¯

**4.1 åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ**
- [ ] å˜ä½“ãƒ†ã‚¹ãƒˆã®æ‹¡å……
  - å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚«ãƒãƒ¬ãƒƒã‚¸80%ä»¥ä¸Š
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè£…
  - AIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®ãƒ†ã‚¹ãƒˆ
  - ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®æ¤œè¨¼
- [ ] E2Eãƒ†ã‚¹ãƒˆã®å®Ÿè£…
  - ãƒ–ãƒ©ã‚¦ã‚¶ãƒ†ã‚¹ãƒˆï¼ˆSelenium/Playwrightï¼‰
  - è¤‡æ•°ç”»åƒã§ã®å‹•ä½œç¢ºèª
- [ ] æ€§èƒ½ãƒ†ã‚¹ãƒˆ
  - å‡¦ç†æ™‚é–“ã®è¨ˆæ¸¬
  - GPU/ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã®ç›£è¦–
  - ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®š

**4.2 æ€§èƒ½æœ€é©åŒ–**
- [ ] GPUãƒ¡ãƒ¢ãƒªã®æœ€é©åŒ–
  - ãƒãƒƒãƒã‚µã‚¤ã‚ºã®èª¿æ•´
  - ãƒ¢ãƒ‡ãƒ«ã®è»½é‡åŒ–æ¤œè¨
- [ ] å‡¦ç†æ™‚é–“ã®çŸ­ç¸®
  - ä¸¦åˆ—å‡¦ç†ã®å°å…¥
  - ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥
- [ ] ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–
- [ ] ç”»åƒã‚µã‚¤ã‚ºã®æœ€é©åŒ–

**4.3 ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–**
- [ ] ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
- [ ] CSRF/XSSå¯¾ç­–ã®ç¢ºèª
- [ ] ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®å®Ÿè£…
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç²¾æŸ»

**4.4 ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™**
- [ ] README.md ã®ä½œæˆ
  - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜
  - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
  - ä½¿ç”¨æ–¹æ³•
- [ ] é–‹ç™ºè€…å‘ã‘ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
  - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£èª¬æ˜
  - APIä»•æ§˜æ›¸
  - ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„
- [ ] ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ‹ãƒ¥ã‚¢ãƒ«
  - æ“ä½œæ‰‹é †
  - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

**4.5 ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæº–å‚™**
- [ ] DockeråŒ–
  - Dockerfileä½œæˆ
  - docker-compose.ymlä½œæˆ
- [ ] æœ¬ç•ªç’°å¢ƒè¨­å®š
  - Gunicornè¨­å®š
  - Nginxè¨­å®š
- [ ] CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  - GitHub Actionsã®è¨­å®š
  - è‡ªå‹•ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

**æˆæœç‰©**
- é«˜å“è³ªãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
- åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
- å®Œå…¨ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½ãªçŠ¶æ…‹

---

## 3. è©³ç´°å®Ÿè£…è¨ˆç”»

### 3.1 Week 1: ç’°å¢ƒæ§‹ç¯‰ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–

**Day 1-2: é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—**
```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ
mkdir -p spot_the_diff/{app/{routes,services,utils,models,static/{css,js,images},templates},models,uploads,outputs,tests,config,scripts,doc}

# UVç’°å¢ƒã®åˆæœŸåŒ–
uv init
uv venv
source .venv/bin/activate

# pyproject.tomlã®è¨­å®š
[project]
name = "spot-the-diff"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "flask>=3.0.0",
    "pillow>=10.0.0",
    "opencv-python>=4.8.0",
    "numpy>=1.24.0",
    "torch>=2.5.0",
    "torchvision>=0.20.0",
    "pytest>=7.4.0",
]
```

**Day 3-4: AIãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**
```python
# scripts/download_models.py
import os
import urllib.request
from pathlib import Path

def download_sam2():
    """SAM 2 Tinyãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    model_dir = Path("models/sam2")
    model_dir.mkdir(parents=True, exist_ok=True)

    url = "https://dl.fbaipublicfiles.com/segment_anything_2/sam2_hiera_tiny.pt"
    output_path = model_dir / "sam2_hiera_tiny.pt"

    if not output_path.exists():
        print("Downloading SAM 2 Tiny...")
        urllib.request.urlretrieve(url, output_path)
        print("Download complete!")

def download_lama():
    """LaMaãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    # Hugging Faceã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    pass

if __name__ == "__main__":
    download_sam2()
    download_lama()
```

**Day 5-7: FlaskåˆæœŸè¨­å®šã¨åŸºæœ¬æ§‹é€ **
```python
# app/__init__.py
from flask import Flask
from config.config import Config

def create_app(config_class=Config):
    app = Flask(__name__)
    app.config.from_object(config_class)

    # ãƒ–ãƒ«ãƒ¼ãƒ—ãƒªãƒ³ãƒˆç™»éŒ²
    from app.routes import main, upload, generate
    app.register_blueprint(main.bp)
    app.register_blueprint(upload.bp)
    app.register_blueprint(generate.bp)

    return app

# run.py
from app import create_app

app = create_app()

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
```

---

### 3.2 Week 2-4: AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…

**Week 2: SAM 2ã¨Saliencyå®Ÿè£…**

```python
# app/services/sam2_service.py
import torch
import numpy as np
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass

@dataclass
class Segment:
    mask: np.ndarray
    bbox: List[int]
    area: int
    score: float
    saliency_score: float = 0.0

class SAM2Service:
    def __init__(self, model_path: str, device: str = 'cuda'):
        self.device = device
        self.model = self._load_model(model_path)

    def _load_model(self, model_path: str):
        """SAM 2ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        from sam2.build_sam import build_sam2
        from sam2.sam2_image_predictor import SAM2ImagePredictor

        checkpoint = Path(model_path)
        config = "sam2_hiera_t.yaml"

        sam2_model = build_sam2(config, checkpoint, device=self.device)
        predictor = SAM2ImagePredictor(sam2_model)
        return predictor

    def segment_image(self, image: np.ndarray,
                     min_area: int = 1000,
                     max_area: int = None) -> List[Segment]:
        """
        ç”»åƒã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–

        Args:
            image: RGBç”»åƒ (H, W, 3)
            min_area: æœ€å°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé¢ç©
            max_area: æœ€å¤§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé¢ç©

        Returns:
            List[Segment]: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆ
        """
        self.model.set_image(image)

        # è‡ªå‹•ãƒã‚¹ã‚¯ç”Ÿæˆ
        masks = self.model.generate(image)

        segments = []
        for mask_data in masks:
            mask = mask_data['segmentation']
            area = mask.sum()

            # é¢ç©ãƒ•ã‚£ãƒ«ã‚¿
            if area < min_area:
                continue
            if max_area and area > max_area:
                continue

            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹è¨ˆç®—
            bbox = self._compute_bbox(mask)

            segment = Segment(
                mask=mask,
                bbox=bbox,
                area=int(area),
                score=float(mask_data.get('stability_score', 0.0))
            )
            segments.append(segment)

        return segments

    def _compute_bbox(self, mask: np.ndarray) -> List[int]:
        """ãƒã‚¹ã‚¯ã‹ã‚‰ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’è¨ˆç®—"""
        rows = np.any(mask, axis=1)
        cols = np.any(mask, axis=0)
        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]
        return [int(cmin), int(rmin), int(cmax), int(rmax)]
```

```python
# app/services/saliency_service.py
import cv2
import numpy as np
from typing import List

class SaliencyService:
    def __init__(self, method: str = 'spectral_residual'):
        """
        Args:
            method: 'spectral_residual', 'fine_grained', 'bing'
        """
        self.method = method
        self.saliency = self._create_saliency_detector()

    def _create_saliency_detector(self):
        if self.method == 'spectral_residual':
            return cv2.saliency.StaticSaliencySpectralResidual_create()
        elif self.method == 'fine_grained':
            return cv2.saliency.StaticSaliencyFineGrained_create()
        else:
            raise ValueError(f"Unknown method: {self.method}")

    def compute_saliency_map(self, image: np.ndarray) -> np.ndarray:
        """
        é¡•è‘—æ€§ãƒãƒƒãƒ—ã‚’ç”Ÿæˆ

        Args:
            image: RGBç”»åƒ (H, W, 3)

        Returns:
            np.ndarray: æ­£è¦åŒ–ã•ã‚ŒãŸé¡•è‘—æ€§ãƒãƒƒãƒ— (H, W) [0.0-1.0]
        """
        success, saliency_map = self.saliency.computeSaliency(image)

        if not success:
            raise RuntimeError("Saliency computation failed")

        # æ­£è¦åŒ–
        saliency_map = cv2.normalize(
            saliency_map, None, 0, 1, cv2.NORM_MINMAX
        )

        return saliency_map

    def compute_segment_saliency(self, saliency_map: np.ndarray,
                                 segment: 'Segment') -> float:
        """
        ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å¹³å‡é¡•è‘—æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—

        Returns:
            float: é¡•è‘—æ€§ã‚¹ã‚³ã‚¢ [0.0-1.0]
        """
        masked_saliency = saliency_map[segment.mask]
        return float(np.mean(masked_saliency))

    def rank_segments(self, segments: List['Segment'],
                     saliency_map: np.ndarray) -> List['Segment']:
        """ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¡•è‘—æ€§ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘"""
        for segment in segments:
            segment.saliency_score = self.compute_segment_saliency(
                saliency_map, segment
            )

        # é¡•è‘—æ€§ã‚¹ã‚³ã‚¢ã®æ˜‡é †ã§ã‚½ãƒ¼ãƒˆï¼ˆä½ã„æ–¹ãŒç›®ç«‹ã¡ã«ãã„ï¼‰
        return sorted(segments, key=lambda s: s.saliency_score)
```

**Week 3: LaMaçµ±åˆã¨è‰²å¤‰æ›´æ©Ÿèƒ½**

```python
# app/services/lama_service.py
import torch
import numpy as np
from pathlib import Path
from PIL import Image

class LaMaService:
    def __init__(self, model_path: str, device: str = 'cuda'):
        self.device = device
        self.model = self._load_model(model_path)

    def _load_model(self, model_path: str):
        """LaMaãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        # LaMaã®å®Ÿè£…ã«å¾“ã£ã¦ãƒ­ãƒ¼ãƒ‰
        checkpoint = torch.load(model_path, map_location=self.device)
        model = ... # LaMaãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        model.load_state_dict(checkpoint)
        model.eval()
        return model

    def inpaint(self, image: np.ndarray, mask: np.ndarray,
                refine: bool = True) -> np.ndarray:
        """
        ç”»åƒè£œå®Œ

        Args:
            image: RGBç”»åƒ (H, W, 3) [0-255]
            mask: ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯ (H, W) [0 or 1]
            refine: ãƒªãƒ•ã‚¡ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆå‡¦ç†

        Returns:
            np.ndarray: è£œå®Œç”»åƒ (H, W, 3) [0-255]
        """
        # å‰å‡¦ç†
        image_tensor = self._preprocess_image(image)
        mask_tensor = self._preprocess_mask(mask)

        # æ¨è«–
        with torch.no_grad():
            output = self.model(image_tensor, mask_tensor)

        # å¾Œå‡¦ç†
        result = self._postprocess(output)

        if refine:
            result = self._refine(result, mask)

        return result

    def _preprocess_image(self, image: np.ndarray) -> torch.Tensor:
        """ç”»åƒã®å‰å‡¦ç†"""
        image = image.astype(np.float32) / 255.0
        image = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0)
        return image.to(self.device)

    def _preprocess_mask(self, mask: np.ndarray) -> torch.Tensor:
        """ãƒã‚¹ã‚¯ã®å‰å‡¦ç†"""
        mask = mask.astype(np.float32)
        mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0)
        return mask.to(self.device)

    def _postprocess(self, output: torch.Tensor) -> np.ndarray:
        """å‡ºåŠ›ã®å¾Œå‡¦ç†"""
        output = output.squeeze(0).permute(1, 2, 0).cpu().numpy()
        output = (output * 255).clip(0, 255).astype(np.uint8)
        return output
```

```python
# app/utils/image_utils.py
import cv2
import numpy as np
from typing import Tuple

def change_color(image: np.ndarray, mask: np.ndarray,
                hue_shift: int = None) -> np.ndarray:
    """
    ç‰©ä½“ã®è‰²ã‚’å¤‰æ›´

    Args:
        image: RGBç”»åƒ
        mask: ãƒã‚¤ãƒŠãƒªãƒã‚¹ã‚¯
        hue_shift: è‰²ç›¸ã‚·ãƒ•ãƒˆé‡ï¼ˆ0-180ï¼‰ã€Noneã®å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ 

    Returns:
        è‰²å¤‰æ›´å¾Œã®ç”»åƒ
    """
    # BGR â†’ HSVå¤‰æ›
    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32)

    # ãƒ©ãƒ³ãƒ€ãƒ ãªè‰²ç›¸ã‚·ãƒ•ãƒˆ
    if hue_shift is None:
        hue_shift = np.random.randint(30, 150)

    # ãƒã‚¹ã‚¯é ˜åŸŸã®è‰²ç›¸ã‚’å¤‰æ›´
    hsv[:, :, 0][mask] = (hsv[:, :, 0][mask] + hue_shift) % 180

    # HSV â†’ RGBå¤‰æ›
    hsv = hsv.astype(np.uint8)
    result = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

    return result

def duplicate_object(image: np.ndarray, segment: 'Segment',
                    offset: Tuple[int, int] = None) -> np.ndarray:
    """
    ç‰©ä½“ã‚’è¤‡è£½ã—ã¦é…ç½®

    Args:
        image: RGBç”»åƒ
        segment: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±
        offset: é…ç½®ã‚ªãƒ•ã‚»ãƒƒãƒˆ (dx, dy)ã€Noneã®å ´åˆã¯è‡ªå‹•è¨ˆç®—

    Returns:
        ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆè¿½åŠ å¾Œã®ç”»åƒ
    """
    result = image.copy()

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé ˜åŸŸã®æŠ½å‡º
    x1, y1, x2, y2 = segment.bbox
    obj_region = image[y1:y2, x1:x2].copy()
    obj_mask = segment.mask[y1:y2, x1:x2]

    # é…ç½®ä½ç½®ã®æ±ºå®š
    if offset is None:
        offset = _find_empty_space(image, segment)

    dx, dy = offset
    new_x1 = x1 + dx
    new_y1 = y1 + dy
    new_x2 = new_x1 + (x2 - x1)
    new_y2 = new_y1 + (y2 - y1)

    # ç”»åƒç¯„å›²å†…ãƒã‚§ãƒƒã‚¯
    if new_x2 > image.shape[1] or new_y2 > image.shape[0]:
        return result

    # ãƒã‚¹ã‚¯é ˜åŸŸã®ã¿ã‚³ãƒ”ãƒ¼
    result[new_y1:new_y2, new_x1:new_x2][obj_mask] = obj_region[obj_mask]

    return result

def _find_empty_space(image: np.ndarray, segment: 'Segment') -> Tuple[int, int]:
    """ç©ºã„ã¦ã„ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ¢ã™"""
    # ç°¡æ˜“å®Ÿè£…ï¼šãƒ©ãƒ³ãƒ€ãƒ ãªã‚ªãƒ•ã‚»ãƒƒãƒˆ
    h, w = image.shape[:2]
    x1, y1, x2, y2 = segment.bbox
    obj_w = x2 - x1
    obj_h = y2 - y1

    max_dx = w - x2 - obj_w
    max_dy = h - y2 - obj_h

    if max_dx > 0 and max_dy > 0:
        dx = np.random.randint(50, max(51, max_dx))
        dy = np.random.randint(50, max(51, max_dy))
        return (dx, dy)

    return (0, 0)
```

**Week 4: ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼å®Ÿè£…**

```python
# app/services/difference_generator.py
import random
import time
from typing import List, Tuple, Dict
from dataclasses import dataclass, asdict
import numpy as np

@dataclass
class Difference:
    id: int
    type: str  # 'deletion', 'color_change', 'addition'
    bbox: List[int]
    polygon: List[List[int]]
    saliency_score: float
    description: str
    original_color: List[int] = None
    new_color: List[int] = None

@dataclass
class GenerationResult:
    modified_image: np.ndarray
    differences: List[Difference]
    metadata: Dict

class DifferenceGenerator:
    def __init__(self, sam2_service, saliency_service, lama_service):
        self.sam2 = sam2_service
        self.saliency = saliency_service
        self.lama = lama_service

        self.difficulty_config = {
            'easy': {'num_changes': 3, 'saliency_max': 0.7},
            'medium': {'num_changes': 5, 'saliency_max': 0.5},
            'hard': {'num_changes': 8, 'saliency_max': 0.3}
        }

    def generate(self, image: np.ndarray,
                difficulty: str = 'medium') -> GenerationResult:
        """é–“é•ã„æ¢ã—ç”»åƒã‚’ç”Ÿæˆ"""
        start_time = time.time()

        # 1. ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        seg_start = time.time()
        segments = self.sam2.segment_image(image)
        seg_time = time.time() - seg_start

        # 2. é¡•è‘—æ€§è§£æ
        sal_start = time.time()
        saliency_map = self.saliency.compute_saliency_map(image)
        ranked_segments = self.saliency.rank_segments(segments, saliency_map)
        sal_time = time.time() - sal_start

        # 3. ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé¸æŠ
        selected = self._select_segments(ranked_segments, difficulty)

        # 4. å¤‰æ›´é©ç”¨
        inp_start = time.time()
        modified_image, differences = self._apply_changes(image, selected)
        inp_time = time.time() - inp_start

        total_time = time.time() - start_time

        # 5. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        metadata = self._create_metadata(
            differences, difficulty,
            seg_time, sal_time, inp_time, total_time
        )

        return GenerationResult(modified_image, differences, metadata)

    def _select_segments(self, segments: List,
                        difficulty: str) -> List:
        """é›£æ˜“åº¦ã«åŸºã¥ã„ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠ"""
        config = self.difficulty_config[difficulty]
        num_changes = config['num_changes']
        saliency_max = config['saliency_max']

        # é¡•è‘—æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered = [s for s in segments
                   if s.saliency_score <= saliency_max]

        # ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        n = min(num_changes, len(filtered))
        return random.sample(filtered, n)

    def _apply_changes(self, image: np.ndarray, segments: List) -> Tuple:
        """å¤‰æ›´ã‚’é©ç”¨"""
        from app.utils.image_utils import change_color, duplicate_object

        modified = image.copy()
        differences = []

        change_types = ['deletion', 'color_change', 'addition']

        for idx, segment in enumerate(segments):
            change_type = random.choice(change_types)

            if change_type == 'deletion':
                modified = self.lama.inpaint(modified, segment.mask)
                desc = "Object removed"

            elif change_type == 'color_change':
                original_color = self._get_avg_color(modified, segment.mask)
                modified = change_color(modified, segment.mask)
                new_color = self._get_avg_color(modified, segment.mask)
                desc = "Color changed"

            elif change_type == 'addition':
                modified = duplicate_object(modified, segment)
                desc = "Object duplicated"

            # PolygonæŠ½å‡ºï¼ˆè¼ªéƒ­ï¼‰
            polygon = self._extract_polygon(segment.mask)

            diff = Difference(
                id=idx + 1,
                type=change_type,
                bbox=segment.bbox,
                polygon=polygon,
                saliency_score=segment.saliency_score,
                description=desc
            )

            if change_type == 'color_change':
                diff.original_color = original_color
                diff.new_color = new_color

            differences.append(diff)

        return modified, differences

    def _get_avg_color(self, image: np.ndarray, mask: np.ndarray) -> List[int]:
        """ãƒã‚¹ã‚¯é ˜åŸŸã®å¹³å‡è‰²ã‚’å–å¾—"""
        colors = image[mask]
        avg_color = np.mean(colors, axis=0).astype(int).tolist()
        return avg_color

    def _extract_polygon(self, mask: np.ndarray) -> List[List[int]]:
        """ãƒã‚¹ã‚¯ã‹ã‚‰è¼ªéƒ­ãƒãƒªã‚´ãƒ³ã‚’æŠ½å‡º"""
        import cv2
        contours, _ = cv2.findContours(
            mask.astype(np.uint8),
            cv2.RETR_EXTERNAL,
            cv2.CHAIN_APPROX_SIMPLE
        )
        if len(contours) > 0:
            largest = max(contours, key=cv2.contourArea)
            polygon = largest.squeeze().tolist()
            return polygon if isinstance(polygon[0], list) else [polygon]
        return []

    def _create_metadata(self, differences, difficulty,
                        seg_time, sal_time, inp_time, total_time) -> Dict:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
        return {
            'difficulty': difficulty,
            'total_differences': len(differences),
            'differences': [asdict(d) for d in differences],
            'processing_steps': {
                'segmentation_time': round(seg_time, 2),
                'saliency_time': round(sal_time, 2),
                'inpainting_time': round(inp_time, 2),
                'total_time': round(total_time, 2)
            },
            'model_versions': {
                'sam2': 'SAM 2 Tiny',
                'lama': 'big-lama',
                'saliency': 'opencv-spectral-residual'
            }
        }
```

---

### 3.3 Week 5-6: Web UIå®Ÿè£…

**Week 5: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API**

```python
# app/routes/upload.py
from flask import Blueprint, request, jsonify, current_app
from werkzeug.utils import secure_filename
import uuid
from pathlib import Path
from app.utils.validation import validate_image_file

bp = Blueprint('upload', __name__, url_prefix='/api')

@bp.route('/upload', methods=['POST'])
def upload_image():
    """ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400

    file = request.files['file']

    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400

    try:
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        validate_image_file(file)

        # å®‰å…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        ext = file.filename.rsplit('.', 1)[1].lower()
        file_id = str(uuid.uuid4())
        filename = f"{file_id}.{ext}"

        # ä¿å­˜
        upload_dir = Path(current_app.config['UPLOAD_FOLDER'])
        upload_dir.mkdir(exist_ok=True)
        filepath = upload_dir / filename
        file.save(filepath)

        # ç”»åƒæƒ…å ±å–å¾—
        from PIL import Image
        img = Image.open(filepath)
        width, height = img.size

        return jsonify({
            'success': True,
            'file_id': file_id,
            'filename': file.filename,
            'size': filepath.stat().st_size,
            'dimensions': [width, height]
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 400
```

```python
# app/routes/generate.py
from flask import Blueprint, request, jsonify, current_app
from concurrent.futures import ThreadPoolExecutor
import uuid
from pathlib import Path

bp = Blueprint('generate', __name__, url_prefix='/api')

# ã‚°ãƒ­ãƒ¼ãƒãƒ«Executor
executor = ThreadPoolExecutor(max_workers=3)

# ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†
job_status = {}

@bp.route('/generate', methods=['POST'])
def generate_difference():
    """é–“é•ã„æ¢ã—ç”Ÿæˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    data = request.json

    file_id = data.get('file_id')
    difficulty = data.get('difficulty', 'medium')

    if not file_id:
        return jsonify({'error': 'file_id is required'}), 400

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    upload_dir = Path(current_app.config['UPLOAD_FOLDER'])
    filepath = next(upload_dir.glob(f"{file_id}.*"), None)

    if not filepath:
        return jsonify({'error': 'File not found'}), 404

    # ã‚¸ãƒ§ãƒ–IDç”Ÿæˆ
    job_id = f"job_{uuid.uuid4().hex}"

    # éåŒæœŸå‡¦ç†é–‹å§‹
    job_status[job_id] = {
        'status': 'queued',
        'progress': 0,
        'current_step': 'Queued'
    }

    executor.submit(process_generation, job_id, filepath, difficulty)

    return jsonify({
        'success': True,
        'job_id': job_id,
        'status': 'queued',
        'estimated_time': 90
    })

def process_generation(job_id, filepath, difficulty):
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†"""
    try:
        from app.services.difference_generator import DifferenceGenerator
        from app import sam2_service, saliency_service, lama_service
        from PIL import Image
        import numpy as np

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
        job_status[job_id] = {
            'status': 'processing',
            'progress': 10,
            'current_step': 'Loading image'
        }

        # ç”»åƒèª­ã¿è¾¼ã¿
        image = np.array(Image.open(filepath))

        # ç”Ÿæˆå‡¦ç†
        job_status[job_id]['progress'] = 30
        job_status[job_id]['current_step'] = 'Segmentation'

        generator = DifferenceGenerator(
            sam2_service, saliency_service, lama_service
        )
        result = generator.generate(image, difficulty)

        # çµæœä¿å­˜
        job_status[job_id]['progress'] = 90
        job_status[job_id]['current_step'] = 'Saving results'

        output_dir = Path('outputs') / job_id
        output_dir.mkdir(parents=True, exist_ok=True)

        # ç”»åƒä¿å­˜
        Image.fromarray(image).save(output_dir / 'original.png')
        Image.fromarray(result.modified_image).save(output_dir / 'modified.png')

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        import json
        with open(output_dir / 'metadata.json', 'w') as f:
            json.dump(result.metadata, f, indent=2)

        # å®Œäº†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        job_status[job_id] = {
            'status': 'completed',
            'progress': 100,
            'current_step': 'Finished',
            'result_path': str(output_dir)
        }

    except Exception as e:
        job_status[job_id] = {
            'status': 'failed',
            'error': str(e)
        }

@bp.route('/status/<job_id>', methods=['GET'])
def get_status(job_id):
    """å‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—"""
    if job_id not in job_status:
        return jsonify({'error': 'Job not found'}), 404

    return jsonify(job_status[job_id])

@bp.route('/result/<job_id>', methods=['GET'])
def get_result(job_id):
    """çµæœå–å¾—"""
    if job_id not in job_status:
        return jsonify({'error': 'Job not found'}), 404

    status = job_status[job_id]

    if status['status'] != 'completed':
        return jsonify({'error': 'Job not completed'}), 400

    output_dir = Path(status['result_path'])

    import json
    with open(output_dir / 'metadata.json') as f:
        metadata = json.load(f)

    return jsonify({
        'success': True,
        'job_id': job_id,
        'original_image_url': f'/outputs/{job_id}/original.png',
        'modified_image_url': f'/outputs/{job_id}/modified.png',
        'metadata': metadata
    })
```

**Week 6: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…**

```html
<!-- templates/upload.html -->
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - é–“é•ã„æ¢ã—è‡ªå‹•ç”Ÿæˆ</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>
    <div class="container">
        <h1>é–“é•ã„æ¢ã—è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ </h1>

        <div class="upload-area" id="uploadArea">
            <div class="upload-icon">ğŸ“·</div>
            <p>ç”»åƒã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—</p>
            <p>ã¾ãŸã¯</p>
            <button class="btn-primary" onclick="document.getElementById('fileInput').click()">
                ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
            </button>
            <input type="file" id="fileInput" accept="image/png,image/jpeg" style="display: none;">
        </div>

        <div id="previewArea" style="display: none;">
            <img id="previewImage" alt="Preview">
            <div class="difficulty-selector">
                <label>é›£æ˜“åº¦:</label>
                <select id="difficulty">
                    <option value="easy">ç°¡å˜</option>
                    <option value="medium" selected>æ™®é€š</option>
                    <option value="hard">é›£ã—ã„</option>
                </select>
            </div>
            <button class="btn-success" id="generateBtn">ç”Ÿæˆé–‹å§‹</button>
        </div>
    </div>

    <script src="{{ url_for('static', filename='js/upload.js') }}"></script>
</body>
</html>
```

```javascript
// static/js/upload.js
const uploadArea = document.getElementById('uploadArea');
const fileInput = document.getElementById('fileInput');
const previewArea = document.getElementById('previewArea');
const previewImage = document.getElementById('previewImage');
const generateBtn = document.getElementById('generateBtn');

let uploadedFileId = null;

// ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—
uploadArea.addEventListener('dragover', (e) => {
    e.preventDefault();
    uploadArea.classList.add('dragover');
});

uploadArea.addEventListener('dragleave', () => {
    uploadArea.classList.remove('dragover');
});

uploadArea.addEventListener('drop', (e) => {
    e.preventDefault();
    uploadArea.classList.remove('dragover');

    const files = e.dataTransfer.files;
    if (files.length > 0) {
        handleFile(files[0]);
    }
});

// ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
fileInput.addEventListener('change', (e) => {
    if (e.target.files.length > 0) {
        handleFile(e.target.files[0]);
    }
});

// ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
async function handleFile(file) {
    // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if (!file.type.startsWith('image/')) {
        alert('ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„');
        return;
    }

    if (file.size > 10 * 1024 * 1024) {
        alert('ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¯10MBä»¥ä¸‹ã«ã—ã¦ãã ã•ã„');
        return;
    }

    // ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    const reader = new FileReader();
    reader.onload = (e) => {
        previewImage.src = e.target.result;
        uploadArea.style.display = 'none';
        previewArea.style.display = 'block';
    };
    reader.readAsDataURL(file);

    // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    const formData = new FormData();
    formData.append('file', file);

    try {
        const response = await fetch('/api/upload', {
            method: 'POST',
            body: formData
        });

        const data = await response.json();

        if (data.success) {
            uploadedFileId = data.file_id;
        } else {
            alert('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: ' + data.error);
        }
    } catch (error) {
        alert('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ' + error.message);
    }
}

// ç”Ÿæˆé–‹å§‹
generateBtn.addEventListener('click', async () => {
    if (!uploadedFileId) {
        alert('ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„');
        return;
    }

    const difficulty = document.getElementById('difficulty').value;

    try {
        const response = await fetch('/api/generate', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                file_id: uploadedFileId,
                difficulty: difficulty
            })
        });

        const data = await response.json();

        if (data.success) {
            // å‡¦ç†ä¸­ãƒšãƒ¼ã‚¸ã¸é·ç§»
            window.location.href = `/processing?job_id=${data.job_id}`;
        } else {
            alert('ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: ' + data.error);
        }
    } catch (error) {
        alert('ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ' + error.message);
    }
});
```

---

### 3.4 Week 7-8: ãƒ†ã‚¹ãƒˆã¨æœ€é©åŒ–

```python
# tests/test_services.py
import pytest
import numpy as np
from app.services.sam2_service import SAM2Service
from app.services.saliency_service import SaliencyService
from app.services.lama_service import LaMaService

@pytest.fixture
def test_image():
    """ãƒ†ã‚¹ãƒˆç”¨ç”»åƒ"""
    return np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)

def test_sam2_segmentation(test_image):
    service = SAM2Service('models/sam2/sam2_hiera_tiny.pt')
    segments = service.segment_image(test_image)

    assert len(segments) > 0
    for segment in segments:
        assert segment.mask.shape == (512, 512)
        assert len(segment.bbox) == 4
        assert segment.area > 0

def test_saliency_computation(test_image):
    service = SaliencyService()
    saliency_map = service.compute_saliency_map(test_image)

    assert saliency_map.shape == (512, 512)
    assert 0 <= saliency_map.min() <= saliency_map.max() <= 1

# ã•ã‚‰ã«ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ...
```

---

### 3.5 Week 9: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™

```markdown
# README.md

# æ¬¡ä¸–ä»£å‹é–“é•ã„æ¢ã—è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

AIæŠ€è¡“ã‚’æ´»ç”¨ã—ã¦ã€ç”»åƒã‹ã‚‰è‡ªå‹•çš„ã«é–“é•ã„æ¢ã—å•é¡Œã‚’ç”Ÿæˆã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚

## ç‰¹å¾´

- **æœ€æ–°AIæŠ€è¡“**: SAM 2ã€LaMaã€é¡•è‘—æ€§è§£æã‚’çµ±åˆ
- **ç°¡å˜æ“ä½œ**: ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§è‡ªå‹•ç”Ÿæˆ
- **é›£æ˜“åº¦èª¿æ•´**: ç°¡å˜ãƒ»æ™®é€šãƒ»é›£ã—ã„ã®3æ®µéš

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦ç’°å¢ƒ

- Python 3.10ä»¥ä¸Š
- CUDAå¯¾å¿œGPU (æ¨å¥¨)
- 16GBä»¥ä¸Šã®RAM

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

\`\`\`bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone <repository_url>
cd NewSpotTheDiff

# UVç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
uv venv
source .venv/bin/activate

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv pip install -e .

# AIãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python scripts/download_models.py
\`\`\`

### èµ·å‹•

\`\`\`bash
python run.py
\`\`\`

ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹

## ä½¿ã„æ–¹

1. ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
2. é›£æ˜“åº¦ã‚’é¸æŠ
3. ã€Œç”Ÿæˆé–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
4. å®Œæˆã—ãŸé–“é•ã„æ¢ã—ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [è¦ä»¶å®šç¾©æ›¸](doc/requirements.md)
- [ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ›¸](doc/system_architecture.md)
- [å®Ÿè£…è¨ˆç”»](doc/implementation_plan.md)

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License
```

---

## 4. ãƒªã‚¹ã‚¯ç®¡ç†ã¨å¯¾å¿œç­–

| ãƒªã‚¹ã‚¯ | ç™ºç”Ÿç¢ºç‡ | å½±éŸ¿åº¦ | å¯¾å¿œç­– |
|--------|---------|--------|---------|
| GPUç’°å¢ƒæ§‹ç¯‰ã®é…å»¶ | ä¸­ | é«˜ | ã‚¯ãƒ©ã‚¦ãƒ‰GPUï¼ˆColabã€AWSï¼‰ã®æº–å‚™ |
| AIãƒ¢ãƒ‡ãƒ«ã®å‡¦ç†æ™‚é–“è¶…é | é«˜ | ä¸­ | è»½é‡ãƒ¢ãƒ‡ãƒ«ã®æ¡ç”¨ã€æ®µéšçš„æœ€é©åŒ– |
| ç”»åƒè£œå®Œå“è³ªã®å•é¡Œ | ä¸­ | ä¸­ | è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã€ãƒã‚¤ãƒ‘ãƒ©èª¿æ•´ |
| ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…ã®é…å»¶ | ä½ | ä½ | ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ´»ç”¨ |

---

## 5. æˆåŠŸåŸºæº–

### MVP (Minimum Viable Product)
- [ ] 1æšã®ç”»åƒã‹ã‚‰é–“é•ã„æ¢ã—ã‚’ç”Ÿæˆã§ãã‚‹
- [ ] 3ã¤ã®é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«ãŒæ©Ÿèƒ½ã™ã‚‹
- [ ] å‡¦ç†æ™‚é–“ãŒ2åˆ†ä»¥å†…
- [ ] ç”Ÿæˆç”»åƒãŒè¦–è¦šçš„ã«è‡ªç„¶

### åˆæœŸãƒªãƒªãƒ¼ã‚¹
- [ ] 10åã®åŒæ™‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾å¿œ
- [ ] UIãŒç›´æ„Ÿçš„ã§ä½¿ã„ã‚„ã™ã„
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒé©åˆ‡
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå®Œå‚™

---

**æ–‡æ›¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0
**æœ€çµ‚æ›´æ–°æ—¥**: 2026-02-08
**ä½œæˆè€…**: Claude Code
